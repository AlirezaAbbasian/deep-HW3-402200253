{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deformable convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your student id: 402200253\n",
      "your name: Alireza Abbasian\n"
     ]
    }
   ],
   "source": [
    "student_id = \"402200253\"\n",
    "student_name = \"Alireza Abbasian\"\n",
    "\n",
    "print(\"your student id:\", student_id)\n",
    "print(\"your name:\", student_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# theory questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"5\" color=\"yellow\">\n",
    "الف) \n",
    "تفاوت شبکه کانولوشنی با شبکه deformable convolutional چیست؟\n",
    "</font>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"4\">\n",
    "شبکه کانوولوشنی معمولی از یک فیلتر با شکل ثابت استفاده میکند\n",
    "به این صورت که هر پیکسل خروجی همواره با یک مربع با سایز و مرکز مشخص متناظر است و \n",
    "اصطلاحا receptive field \n",
    "آن مشخص است.\n",
    "ولی در شبکه deformable convolutional\n",
    "از یک فیلتر با شکل متغیر استفاده میکند.\n",
    "به این صورت که هر field of view\n",
    "هر پیکسل خروجی متناسب با ورودی تغییر میکنید!\n",
    "ایده آل ما این است که مثلا اگر سایز فیلتر 3*3\n",
    "است آن 9 پیکسل ورودی که قرار است به آن حساس باشیم\n",
    "بتواند به صورت ایده آل متناسب با اینکه چه آبجکتی در مرکز \n",
    "grid\n",
    "است تا جای ممکن کل آبجکت را دربرگیرد.\n",
    "در حقیقت در کانولوشن معمولی اگر سایز آبجکت در تصویر بزرگ شود ما کاملا\n",
    "بی تفاوت هستیم و همواره با یک فیلتر ثابت کار میکنیم.\n",
    "ولی در deformable convolutional\n",
    "ما میتوانیم با تغییر فیلتر متناسب با آبجکتی که در مرکز\n",
    "grid\n",
    "است کل آبجکت را دربرگیریم.\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"5\" color=\"yellow\">\n",
    "ب)\n",
    "شبکه deformable convolutional\n",
    "چگونه نسبت به Geometric Transformations\n",
    "مقاوم است؟\n",
    "</font>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"4\">\n",
    "\n",
    "در شبکه deformable convolutional\n",
    "ما میتوانیم با تغییر فیلتر متناسب با آبجکتی که در مرکز\n",
    "grid\n",
    "است کل آبجکت را دربرگیریم.\n",
    "به این صورت که field of view\n",
    "هر پیکسل خروجی متناسب با ورودی تغییر میکنید!\n",
    "\n",
    "یعنی مثلا فیلتر کوچک 3*3\n",
    "اگر در مرکز آبجکتی باشد که بزرگتر از فیلتر است. \n",
    "پیکسل های فیلتر با آفست های متفاوت در نقاط مهم آبجکت قرار میگیرند تا بتوانند با آن \n",
    "مثل یک تصویر کوچک رفتار کنند!\n",
    "یا مثلا اگر آبچکتی بچرخد\n",
    "نقاط فیلتر هم در جاهای مهم تصویر چرخش میکنند تا بتوانند باز مثل یک تصویر کوچک صاف بون چرخش با آن رفتار کنند.\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"5\" color=\"yellow\">\n",
    "ج)\n",
    "چرا شبکه کانولوشنی معمولی نسبت به چرخش\n",
    "مقاوم نیست؟\n",
    "</font>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"4\">\n",
    "توجه کنید که شبکه کانوولوشنی معمولی به انتقال آبجکت در تصویر کاملا مقاوم است\n",
    "چرا که فیلتر در کل تصویر پیمایش میشود و هر جا آبجکت وجود داشته باشد ما آن را شناسایی میکنیم.\n",
    "اما اگر آبجکت بچرخد یا بزرگ شود ما دیگر نمیتوانیم آن را شناسایی کنیم.\n",
    "چرا که صرفا فیچرهایی با سایز فیلتر  را یادگرفته بودیم\n",
    "\n",
    "به عبارت دیگر تغییر سایز و چرخش از دید یک فیلتر کوچک ساده و با سایز ثابت\n",
    "مثل یک تصویر جدید است و اصلا نمیتواند خروجی ولیدی به ما بدهد\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"5\" color=\"yellow\">\n",
    "د)\n",
    "چگونه\n",
    "offset\n",
    "مربوط به deformable convolutional\n",
    "را یاد میگیریم؟\n",
    "</font>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"4\">\n",
    "ابتدا چند نام گذاری طبق مقاله انجام میدهیم تا بهتر بتوانیم موضوع را توضیح دهیم.\n",
    "\n",
    "سایز فیلتر را N مینامیم.\n",
    "مثلا اگر سایز فیلتر 3*3 باشد، N=9 است.\n",
    "\n",
    "هر پیکسل خروجی حاصل ضرب داخلی فیلتر با ورودی است.\n",
    "پس نظیر هر پیکسل خروجی باید N \n",
    "تا آفست یادبگیریم تا بدانیم هر کدام از نقاط فیلتر باید در کجای ورودی قرار بگیرد.\n",
    "\n",
    "این آفست ها را به سادگی با یک لایه کانولوشنی یاد میگیریم.\n",
    "یعنی یک لایه داریم که ورودی آن همان تصویر ورودی است و خروجی آن به سایز تصویر خروجی ضرب در N است.\n",
    "یعنی لایه خروجی آفست ها یک تصویر هم سایز خروجی با عمق N است.\n",
    "که هر پیکسل آن نشان دهنده آفست های مربوط به آن پیکسل خروجی است.\n",
    "\n",
    "حال لایه کانولوشنی اصلی برای تولید هر پیکسل خروجی به پیکسل نشان دهنده آفست های مربوطه میرود و با کمک آنها\n",
    "میفهمد باید وزن های فیلتر را در کدام پیکسل های ورودی ضرب کند.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomAffine, RandomRotation\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"4\">\n",
    "توجه کنید که من از دیتاست MNIST\n",
    "برای این تمرین استفاده کرده ام.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"4\">\n",
    "در این قسمت ابتدا میانگین و جذر واریانس دیتاست را استخراج کردم تا در لود کردن دیتا ست به کمک این مقادیر \n",
    "دیتاست را نرمال کنم.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1402)\n",
    "np.random.seed(1402)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of dataset =  tensor(0.1307)\n",
      "std of dataset =  tensor(0.3081)\n",
      "max of dataset after normalization =  2.8215432167053223\n",
      "min of dataset after normalization =  -0.42407387495040894\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean and variance of MNIST dataset\n",
    "mnist_dataset = MNIST('./data/', train=True, download=True, transform=ToTensor())\n",
    "mnist_data = torch.cat([img for img, _ in mnist_dataset], dim=0)\n",
    "mean_value = torch.mean(mnist_data)\n",
    "var_value = torch.var(mnist_data)\n",
    "std_div = torch.sqrt(var_value)\n",
    "print(\"mean of dataset = \",mean_value)\n",
    "print(\"std of dataset = \",std_div)\n",
    "# find max value of dataset after normalization\n",
    "mnist_data = (mnist_data - mean_value) / std_div\n",
    "max_value_in_mnist = torch.max(mnist_data).item()\n",
    "min_value_in_mnist = torch.min(mnist_data).item()\n",
    "print(\"max of dataset after normalization = \",max_value_in_mnist)\n",
    "print(\"min of dataset after normalization = \",min_value_in_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<font face=\"B Nazanin\" size=\"4\">\n",
    "در زیر مشاهده میکنید که دو دیتالودر برای ترین و تست نوشته ام که هر دو دیتا را ابتدا به\n",
    "تنسور تبدیل میکنند سپس آن را نرمالایز میکنند.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((mean_value,), (std_div,)),\n",
    "])\n",
    "\n",
    "# Create DataLoader for training set\n",
    "train_loader = DataLoader(\n",
    "    MNIST('./data/', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# Create DataLoader for test set\n",
    "test_loader = DataLoader(\n",
    "    MNIST('./data/', train=False, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normal convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, layer1_out=16, layer2_out=32, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, layer1_out, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(layer1_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(layer1_out, layer2_out, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(layer2_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7 * 7 * layer2_out, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs=5, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "\n",
    "    train_losses = []\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(average_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print('Training Time: {:.2f} seconds'.format(training_time))\n",
    "\n",
    "    return model, train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels) * 100\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted') * 100\n",
    "\n",
    "    return accuracy, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.1375\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0634\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1175\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1156\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0731\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0300\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0383\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0418\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0295\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0165\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0122\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0300\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0535\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0320\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0219\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0143\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0794\n",
      "Epoch [3/5], Step [600/600], Loss: 0.1123\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0114\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0428\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0130\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0385\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0887\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0178\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0612\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0212\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0040\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0138\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0148\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0083\n",
      "Training Time: 64.74 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model_simple = SimpleCNN(16,32, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion_simple = nn.CrossEntropyLoss()\n",
    "optimizer_simple = torch.optim.Adam(model_simple.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "model_simple, train_losses_simple = train(model_simple, train_loader, criterion_simple, optimizer_simple,\n",
    "                                                   num_epochs=num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple CNN:\n",
      "Training Set Accuracy: 99.35 %\n",
      "Training Set Precision: 99.35 %\n",
      "Test Set Accuracy: 98.89 %\n",
      "Test Set Precision: 98.90 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the training set\n",
    "print('Simple CNN:')\n",
    "train_accuracy, train_precision = test(model_simple, train_loader, device)\n",
    "print('Training Set Accuracy: {:.2f} %'.format(train_accuracy))\n",
    "print('Training Set Precision: {:.2f} %'.format(train_precision))\n",
    "\n",
    "# Test the model on the test set\n",
    "test_accuracy, test_precision = test(model_simple, test_loader, device)\n",
    "print('Test Set Accuracy: {:.2f} %'.format(test_accuracy))\n",
    "print('Test Set Precision: {:.2f} %'.format(test_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deformable convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeformableConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 padding=1,\n",
    "                 bias=True):\n",
    "\n",
    "        super(DeformableConv, self).__init__()\n",
    "\n",
    "        self.padding = padding\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.offset_layer = nn.Conv2d(in_channels, \n",
    "                                     2 * kernel_size * kernel_size,\n",
    "                                     kernel_size=kernel_size, \n",
    "                                     stride=1,\n",
    "                                     padding=self.padding, \n",
    "                                     bias=True)\n",
    "\n",
    "        nn.init.constant_(self.offset_layer.weight, 0.0)\n",
    "        nn.init.constant_(self.offset_layer.bias, 0.0)\n",
    "\n",
    "        \n",
    "        self.grid_conv = nn.Conv2d(in_channels=in_channels,\n",
    "                                      out_channels=out_channels,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      stride=kernel_size,\n",
    "                                      padding=self.padding,\n",
    "                                      bias=bias)\n",
    "        \n",
    "        h = 14\n",
    "        w = 14\n",
    "        k = kernel_size\n",
    "        r_k = (k-1)/2\n",
    "\n",
    "        defaul_grid = torch.zeros(h*k,w*k,2)\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                for m in range(k):\n",
    "                    for n in range(k):\n",
    "                        defaul_grid[i*k+m,j*k+n,1] = i-r_k+m\n",
    "                        defaul_grid[i*k+m,j*k+n,0] = j-r_k+n\n",
    "\n",
    "        defaul_grid = ((defaul_grid / (h-1))-0.5)*2\n",
    "\n",
    "        self.defaul_grid = defaul_grid.to(device)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        offset = self.offset_layer(x).clamp(-0.5, 0.5)\n",
    "\n",
    "        # Reshape and permute dimensions to achieve the desired output size\n",
    "        reshaped_offset = offset.view(b,2, self.kernel_size, self.kernel_size, h, w).permute(0,4,2,5,3,1)\n",
    "        # Reshape to the final size\n",
    "        reshaped_offset = reshaped_offset.contiguous().view(b,h*self.kernel_size, w*self.kernel_size, 2)\n",
    "\n",
    "        map_grid = self.defaul_grid.expand(b, -1, -1, -1)\n",
    "        \n",
    "        map_grid = self.defaul_grid + reshaped_offset\n",
    "\n",
    "        x_deformed = F.grid_sample(x, map_grid, mode='nearest', padding_mode='zeros', align_corners=True)\n",
    "\n",
    "        # Apply regular convolution to the deformed input\n",
    "        x_deformed = self.grid_conv(x_deformed)\n",
    "\n",
    "        return x_deformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeformableCNN(SimpleCNN):\n",
    "    def __init__(self, layer1_out=16, layer2_out=32, num_classes=10):\n",
    "        super(DeformableCNN, self).__init__(layer1_out, layer2_out, num_classes)\n",
    "\n",
    "        self.deformable_layer = nn.Sequential(\n",
    "            DeformableConv(layer1_out, layer2_out, kernel_size=5, padding=2, bias=True),\n",
    "            nn.BatchNorm2d(layer2_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.deformable_layer(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.1513\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0925\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0495\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0510\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0673\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0707\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0360\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0044\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0181\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0947\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0852\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0734\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0232\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0065\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0146\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0211\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0536\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0035\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0442\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0037\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0541\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0129\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0152\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0908\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0031\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0168\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0025\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0202\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0211\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0015\n",
      "Training Time: 79.98 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model_dformable = DeformableCNN(16,32,num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion_dformable = nn.CrossEntropyLoss()\n",
    "optimizer_dformable = torch.optim.Adam(model_dformable.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "model_dformable, train_losses_dformable = train(model_dformable, train_loader, criterion_dformable, optimizer_dformable,\n",
    "                                                   num_epochs=num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deformable CNN:\n",
      "Training Set Accuracy: 99.29 %\n",
      "Training Set Precision: 99.30 %\n",
      "Test Set Accuracy: 98.83 %\n",
      "Test Set Precision: 98.84 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the training set\n",
    "print('deformable CNN:')\n",
    "train_accuracy, train_precision = test(model_dformable, train_loader, device)\n",
    "print('Training Set Accuracy: {:.2f} %'.format(train_accuracy))\n",
    "print('Training Set Precision: {:.2f} %'.format(train_precision))\n",
    "\n",
    "# Test the model on the test set\n",
    "test_accuracy, test_precision = test(model_dformable, test_loader, device)\n",
    "print('Test Set Accuracy: {:.2f} %'.format(test_accuracy))\n",
    "print('Test Set Precision: {:.2f} %'.format(test_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# augment mnist dataset\n",
    "\n",
    "## rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    RandomRotation(degrees=(-90, 90)),  # Random rotation between -15 and 15 degrees\n",
    "    RandomAffine(degrees=0, scale=(0.6, 1.4)),  # Random scale between 0.8 and 1.2\n",
    "    ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "])\n",
    "\n",
    "# Create DataLoader for training set\n",
    "train_loader = DataLoader(\n",
    "    MNIST('./data/', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "# Create DataLoader for test set\n",
    "test_loader = DataLoader(\n",
    "    MNIST('./data/', train=False, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.7086\n",
      "Epoch [1/5], Step [200/600], Loss: 0.6001\n",
      "Epoch [1/5], Step [300/600], Loss: 0.4846\n",
      "Epoch [1/5], Step [400/600], Loss: 0.4295\n",
      "Epoch [1/5], Step [500/600], Loss: 0.4401\n",
      "Epoch [1/5], Step [600/600], Loss: 0.3960\n",
      "Epoch [2/5], Step [100/600], Loss: 0.5092\n",
      "Epoch [2/5], Step [200/600], Loss: 0.2816\n",
      "Epoch [2/5], Step [300/600], Loss: 0.5531\n",
      "Epoch [2/5], Step [400/600], Loss: 0.3697\n",
      "Epoch [2/5], Step [500/600], Loss: 0.3116\n",
      "Epoch [2/5], Step [600/600], Loss: 0.3060\n",
      "Epoch [3/5], Step [100/600], Loss: 0.2740\n",
      "Epoch [3/5], Step [200/600], Loss: 0.3135\n",
      "Epoch [3/5], Step [300/600], Loss: 0.2934\n",
      "Epoch [3/5], Step [400/600], Loss: 0.2595\n",
      "Epoch [3/5], Step [500/600], Loss: 0.1386\n",
      "Epoch [3/5], Step [600/600], Loss: 0.2380\n",
      "Epoch [4/5], Step [100/600], Loss: 0.1557\n",
      "Epoch [4/5], Step [200/600], Loss: 0.2072\n",
      "Epoch [4/5], Step [300/600], Loss: 0.2143\n",
      "Epoch [4/5], Step [400/600], Loss: 0.2936\n",
      "Epoch [4/5], Step [500/600], Loss: 0.2137\n",
      "Epoch [4/5], Step [600/600], Loss: 0.1744\n",
      "Epoch [5/5], Step [100/600], Loss: 0.3855\n",
      "Epoch [5/5], Step [200/600], Loss: 0.2665\n",
      "Epoch [5/5], Step [300/600], Loss: 0.2004\n",
      "Epoch [5/5], Step [400/600], Loss: 0.3902\n",
      "Epoch [5/5], Step [500/600], Loss: 0.1803\n",
      "Epoch [5/5], Step [600/600], Loss: 0.2247\n",
      "Training Time: 83.21 seconds\n"
     ]
    }
   ],
   "source": [
    "model_simple = SimpleCNN(16,32, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion_simple = nn.CrossEntropyLoss()\n",
    "optimizer_simple = torch.optim.Adam(model_simple.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "model_simple, train_losses_simple = train(model_simple, train_loader, criterion_simple, optimizer_simple,\n",
    "                                                   num_epochs=num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple CNN:\n",
      "Training Set Accuracy: 93.47 %\n",
      "Training Set Precision: 93.63 %\n",
      "Test Set Accuracy: 94.20 %\n",
      "Test Set Precision: 94.33 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the training set\n",
    "print('Simple CNN:')\n",
    "train_accuracy, train_precision = test(model_simple, train_loader, device)\n",
    "print('Training Set Accuracy: {:.2f} %'.format(train_accuracy))\n",
    "print('Training Set Precision: {:.2f} %'.format(train_precision))\n",
    "\n",
    "# Test the model on the test set\n",
    "test_accuracy, test_precision = test(model_simple, test_loader, device)\n",
    "print('Test Set Accuracy: {:.2f} %'.format(test_accuracy))\n",
    "print('Test Set Precision: {:.2f} %'.format(test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.7159\n",
      "Epoch [1/5], Step [200/600], Loss: 0.6617\n",
      "Epoch [1/5], Step [300/600], Loss: 0.4699\n",
      "Epoch [1/5], Step [400/600], Loss: 0.2672\n",
      "Epoch [1/5], Step [500/600], Loss: 0.3240\n",
      "Epoch [1/5], Step [600/600], Loss: 0.3838\n",
      "Epoch [2/5], Step [100/600], Loss: 0.2858\n",
      "Epoch [2/5], Step [200/600], Loss: 0.4537\n",
      "Epoch [2/5], Step [300/600], Loss: 0.2726\n",
      "Epoch [2/5], Step [400/600], Loss: 0.3833\n",
      "Epoch [2/5], Step [500/600], Loss: 0.2158\n",
      "Epoch [2/5], Step [600/600], Loss: 0.3137\n",
      "Epoch [3/5], Step [100/600], Loss: 0.3283\n",
      "Epoch [3/5], Step [200/600], Loss: 0.3183\n",
      "Epoch [3/5], Step [300/600], Loss: 0.3046\n",
      "Epoch [3/5], Step [400/600], Loss: 0.2676\n",
      "Epoch [3/5], Step [500/600], Loss: 0.2574\n",
      "Epoch [3/5], Step [600/600], Loss: 0.2342\n",
      "Epoch [4/5], Step [100/600], Loss: 0.2759\n",
      "Epoch [4/5], Step [200/600], Loss: 0.1996\n",
      "Epoch [4/5], Step [300/600], Loss: 0.2247\n",
      "Epoch [4/5], Step [400/600], Loss: 0.3127\n",
      "Epoch [4/5], Step [500/600], Loss: 0.2680\n",
      "Epoch [4/5], Step [600/600], Loss: 0.3020\n",
      "Epoch [5/5], Step [100/600], Loss: 0.2911\n",
      "Epoch [5/5], Step [200/600], Loss: 0.3747\n",
      "Epoch [5/5], Step [300/600], Loss: 0.3136\n",
      "Epoch [5/5], Step [400/600], Loss: 0.2374\n",
      "Epoch [5/5], Step [500/600], Loss: 0.2568\n",
      "Epoch [5/5], Step [600/600], Loss: 0.2218\n",
      "Training Time: 116.12 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model_dformable = DeformableCNN(16,32,num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion_dformable = nn.CrossEntropyLoss()\n",
    "optimizer_dformable = torch.optim.Adam(model_dformable.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "model_dformable, train_losses_dformable = train(model_dformable, train_loader, criterion_dformable, optimizer_dformable,\n",
    "                                                   num_epochs=num_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deformable CNN:\n",
      "Training Set Accuracy: 92.32 %\n",
      "Training Set Precision: 92.62 %\n",
      "Test Set Accuracy: 92.72 %\n",
      "Test Set Precision: 93.02 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the training set\n",
    "print('deformable CNN:')\n",
    "train_accuracy, train_precision = test(model_dformable, train_loader, device)\n",
    "print('Training Set Accuracy: {:.2f} %'.format(train_accuracy))\n",
    "print('Training Set Precision: {:.2f} %'.format(train_precision))\n",
    "\n",
    "# Test the model on the test set\n",
    "test_accuracy, test_precision = test(model_dformable, test_loader, device)\n",
    "print('Test Set Accuracy: {:.2f} %'.format(test_accuracy))\n",
    "print('Test Set Precision: {:.2f} %'.format(test_precision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
